{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "from resizeimage import resizeimage\n",
    "import os\n",
    "import re\n",
    "from numpy import asarray\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pickle_data(data,name):\n",
    "    import pickle\n",
    "    f = open(name,'wb')\n",
    "    pickle.dump(data,f)\n",
    "    \n",
    "def unpickle_data(name):\n",
    "    import pickle\n",
    "    o = open(name,'rb')\n",
    "    data = pickle.load(o,encoding='bytes')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = unpickle_data('New_Mask_Training.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[0]['Y_Med']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = X.reshape(-1,512,512,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = data[0]['Y_Med']\n",
    "Y = Y.reshape(-1,512,512,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n"
     ]
    }
   ],
   "source": [
    "import tflearn\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d, avg_pool_2d, upsample_2d, conv_2d_transpose\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected, flatten \n",
    "from tflearn.layers.estimator import regression\n",
    "from tflearn.layers.normalization import local_response_normalization\n",
    "from tflearn.layers.merge_ops import merge\n",
    "from tflearn.activations import sigmoid\n",
    "#from tflearn.objectives import weighted_crossentropy\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def side_branch(x, factor):\n",
    "    x = conv_2d(x, 1, 1, activation='linear')\n",
    "    kernel = factor*2\n",
    "    x = conv_2d_transpose(x, 1, kernel, [512, 512], strides=factor, activation='linear', bias=False)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input ---(?, 512, 512, 1)\n",
      "b1c1 --- (?, 512, 512, 64)\n",
      "b1c2 --- (?, 512, 512, 64)\n",
      "b1p --- (?, 256, 256, 64)\n",
      "b2c1 --- (?, 256, 256, 128)\n",
      "b2c2 --- (?, 256, 256, 128)\n",
      "b2p --- (?, 128, 128, 128)\n",
      "b3c1 --- (?, 128, 128, 256)\n",
      "b3c2 --- (?, 128, 128, 256)\n",
      "b3c3 --- (?, 128, 128, 256)\n",
      "b3p --- (?, 64, 64, 256)\n",
      "b4c1 --- (?, 64, 64, 512)\n",
      "b4c2 --- (?, 64, 64, 512)\n",
      "b4c3 --- (?, 64, 64, 512)\n",
      "b4p --- (?, 32, 32, 512)\n",
      "b5c1 --- (?, 32, 32, 512)\n",
      "b5c2 --- (?, 32, 32, 512)\n",
      "b5c3 --- (?, 32, 32, 512)\n",
      "merge --- (?, 512, 512, 5)\n",
      "fused --- (?, 512, 512, 1)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "net = input_data(shape=[None, 512, 512, 1], name='input_data')\n",
    "print('input ---'+str(net.shape))\n",
    "\n",
    "\n",
    "\n",
    "#block 1\n",
    "x = conv_2d(net, 64, 3, activation='relu', name='b1c1')\n",
    "print('b1c1 --- '+str(x.shape))\n",
    "\n",
    "x = conv_2d(x, 64, 3, activation='relu', name='b1c2')\n",
    "print('b1c2 --- '+str(x.shape))\n",
    "\n",
    "b1 = side_branch(x, 1)\n",
    "\n",
    "x = max_pool_2d(x, 2, strides=2, name='b1p')\n",
    "print('b1p --- '+str(x.shape))\n",
    "\n",
    "\n",
    "\n",
    "#block 2\n",
    "x = conv_2d(x, 128, 3, activation='relu', name='b2c1')\n",
    "print('b2c1 --- '+str(x.shape))\n",
    "\n",
    "x = conv_2d(x, 128, 3, activation='relu', name='b2c2')\n",
    "print('b2c2 --- '+str(x.shape))\n",
    "\n",
    "b2 = side_branch(x, 2)\n",
    "\n",
    "x = max_pool_2d(x, 2, strides=2, name='b2p')\n",
    "print('b2p --- '+str(x.shape))\n",
    "\n",
    "\n",
    "\n",
    "#block 3\n",
    "x = conv_2d(x, 256, 3, activation='relu', name='b3c1')\n",
    "print('b3c1 --- '+str(x.shape))\n",
    "\n",
    "x = conv_2d(x, 256, 3, activation='relu', name='b3c2')\n",
    "print('b3c2 --- '+str(x.shape))\n",
    "\n",
    "x = conv_2d(x, 256, 3, activation='relu', name='b3c3')\n",
    "print('b3c3 --- '+str(x.shape))\n",
    "\n",
    "b3 = side_branch(x, 4)\n",
    "\n",
    "x = max_pool_2d(x, 2, strides=2, name='b3p')\n",
    "print('b3p --- '+str(x.shape))\n",
    "\n",
    "\n",
    "\n",
    "#block 4\n",
    "x = conv_2d(x, 512, 3, activation='relu', name='b4c1')\n",
    "print('b4c1 --- '+str(x.shape))\n",
    "\n",
    "x = conv_2d(x, 512, 3, activation='relu', name='b4c2')\n",
    "print('b4c2 --- '+str(x.shape))\n",
    "\n",
    "x = conv_2d(x, 512, 3, activation='relu', name='b4c3')\n",
    "print('b4c3 --- '+str(x.shape))\n",
    "\n",
    "b4 = side_branch(x, 8)\n",
    "\n",
    "x = max_pool_2d(x, 2, strides=2, name='b4p')\n",
    "print('b4p --- '+str(x.shape))\n",
    "\n",
    "\n",
    "\n",
    "#block 5\n",
    "x = conv_2d(x, 512, 3, activation='relu', name='b5c1')\n",
    "print('b5c1 --- '+str(x.shape))\n",
    "\n",
    "x = conv_2d(x, 512, 3, activation='relu', name='b5c2')\n",
    "print('b5c2 --- '+str(x.shape))\n",
    "\n",
    "x = conv_2d(x, 512, 3, activation='relu', name='b5c3')\n",
    "print('b5c3 --- '+str(x.shape))\n",
    "\n",
    "b5 = side_branch(x, 16)\n",
    "\n",
    "\n",
    "\n",
    "#FUSE\n",
    "fuse = merge([b1, b2, b3, b4, b5], 'concat', axis=-1, name='merge')\n",
    "print('merge --- '+str(fuse.shape))\n",
    "\n",
    "fuse = conv_2d(fuse, 1, 1, activation='linear', name='fused')\n",
    "print('fused --- '+str(fuse.shape))\n",
    "\n",
    "\n",
    "o1 = sigmoid(b1)\n",
    "o2 = sigmoid(b2)\n",
    "o3 = sigmoid(b3)\n",
    "o4 = sigmoid(b4)\n",
    "o5 = sigmoid(b5)\n",
    "ofuse = sigmoid(fuse)\n",
    "\n",
    "\n",
    "#e1 = regression(o1, optimizer='adam', learning_rate=0.001, loss='weak_cross_entropy_2d', name='o1')\n",
    "#e2 = regression(o2, optimizer='adam', learning_rate=0.001, loss='weak_cross_entropy_2d', name='o2')\n",
    "#e3 = regression(o3, optimizer='adam', learning_rate=0.001, loss='weak_cross_entropy_2d', name='o3')\n",
    "#e4 = regression(o4, optimizer='adam', learning_rate=0.001, loss='weak_cross_entropy_2d', name='o4')\n",
    "#e5 = regression(o5, optimizer='adam', learning_rate=0.001, loss='weak_cross_entropy_2d', name='o5')\n",
    "efuse = regression(ofuse, optimizer='adam', learning_rate=0.001, loss='weak_cross_entropy_2d', name='ofuse')\n",
    "#efuse = regression(ofuse, optimizer='adam', learning_rate=0.001, loss='categorical_crossentropy', name='ofuse')\n",
    "\n",
    "\n",
    "\n",
    "model = tflearn.DNN(net, checkpoint_path='model_googlenet', max_checkpoints=1, tensorboard_verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'numpy.ndarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-5a4489f63aa5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m model.fit({X}, {Y}, n_epoch=10, validation_set=0.1, shuffle=True,\n\u001b[0m\u001b[0;32m      2\u001b[0m           \u001b[0mshow_metric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msnapshot_step\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m           snapshot_epoch=False)\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'"
     ]
    }
   ],
   "source": [
    "model.fit(X, Y, n_epoch=10, validation_set=0.1, shuffle=True,\n",
    "          show_metric=True, snapshot_step=200,\n",
    "          snapshot_epoch=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'o1':Y,'o2':Y,'o3':Y,'o4':Y,'o5':Y,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "Run id: 410V21\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 201\n",
      "Validation samples: 23\n",
      "--\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[64,512,512,64]\n\t [[Node: b1c1/Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](_recv_input_data/X_0/_101, b1c1/W/read)]]\n\t [[Node: Adam/clip_by_global_norm/Adam/clip_by_global_norm/_8/_205 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_887_Adam/clip_by_global_norm/Adam/clip_by_global_norm/_8\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'b1c1/Conv2D', defined at:\n  File \"C:\\Users\\Shachi Shah\\Anaconda3\\lib\\runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\Shachi Shah\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Shachi Shah\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Shachi Shah\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\Shachi Shah\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Users\\Shachi Shah\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\Shachi Shah\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\Shachi Shah\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Shachi Shah\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\Shachi Shah\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\Shachi Shah\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\Shachi Shah\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Shachi Shah\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\Shachi Shah\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\Shachi Shah\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\Shachi Shah\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Shachi Shah\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\Shachi Shah\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\Shachi Shah\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\Shachi Shah\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-28-9fcb33de5cb3>\", line 10, in <module>\n    x = conv_2d(net, 64, 3, activation='relu', name='b1c1')\n  File \"C:\\Users\\Shachi Shah\\Anaconda3\\lib\\site-packages\\tflearn\\layers\\conv.py\", line 99, in conv_2d\n    inference = tf.nn.conv2d(incoming, W, strides, padding)\n  File \"C:\\Users\\Shachi Shah\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 403, in conv2d\n    data_format=data_format, name=name)\n  File \"C:\\Users\\Shachi Shah\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"C:\\Users\\Shachi Shah\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"C:\\Users\\Shachi Shah\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[64,512,512,64]\n\t [[Node: b1c1/Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](_recv_input_data/X_0/_101, b1c1/W/read)]]\n\t [[Node: Adam/clip_by_global_norm/Adam/clip_by_global_norm/_8/_205 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_887_Adam/clip_by_global_norm/Adam/clip_by_global_norm/_8\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\Shachi Shah\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1038\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1040\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Shachi Shah\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1021\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1022\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Shachi Shah\\Anaconda3\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Shachi Shah\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[1;34m()\u001b[0m\n\u001b[0;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 466\u001b[1;33m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[0;32m    467\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[64,512,512,64]\n\t [[Node: b1c1/Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](_recv_input_data/X_0/_101, b1c1/W/read)]]\n\t [[Node: Adam/clip_by_global_norm/Adam/clip_by_global_norm/_8/_205 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_887_Adam/clip_by_global_norm/Adam/clip_by_global_norm/_8\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-8801653bcd7a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m model.fit({'input_data':X}, {'ofuse':Y}, n_epoch=10, validation_set=0.1,\n\u001b[1;32m----> 2\u001b[1;33m           show_metric=True, snapshot_step=200, snapshot_epoch=False)\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Shachi Shah\\Anaconda3\\lib\\site-packages\\tflearn\\models\\dnn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X_inputs, Y_targets, n_epoch, validation_set, show_metric, batch_size, shuffle, snapshot_epoch, snapshot_step, excl_trainops, validation_batch_size, run_id, callbacks)\u001b[0m\n\u001b[0;32m    213\u001b[0m                          \u001b[0mexcl_trainops\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexcl_trainops\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m                          \u001b[0mrun_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrun_id\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 215\u001b[1;33m                          callbacks=callbacks)\n\u001b[0m\u001b[0;32m    216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Shachi Shah\\Anaconda3\\lib\\site-packages\\tflearn\\helpers\\trainer.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, feed_dicts, n_epoch, val_feed_dicts, show_metric, snapshot_step, snapshot_epoch, shuffle_all, dprep_dict, daug_dict, excl_trainops, run_id, callbacks)\u001b[0m\n\u001b[0;32m    334\u001b[0m                                                        \u001b[1;33m(\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_checkpoint_path\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m|\u001b[0m \u001b[0msnapshot_epoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m                                                        \u001b[0msnapshot_step\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 336\u001b[1;33m                                                        show_metric)\n\u001b[0m\u001b[0;32m    337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m                             \u001b[1;31m# Update training state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Shachi Shah\\Anaconda3\\lib\\site-packages\\tflearn\\helpers\\trainer.py\u001b[0m in \u001b[0;36m_train\u001b[1;34m(self, training_step, snapshot_epoch, snapshot_step, show_metric)\u001b[0m\n\u001b[0;32m    775\u001b[0m         \u001b[0mtflearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_training\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    776\u001b[0m         _, train_summ_str = self.session.run([self.train, self.summ_op],\n\u001b[1;32m--> 777\u001b[1;33m                                              feed_batch)\n\u001b[0m\u001b[0;32m    778\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[1;31m# Retrieve loss value from summary string\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Shachi Shah\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    776\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 778\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    779\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Shachi Shah\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    980\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 982\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    983\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Shachi Shah\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1030\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1032\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1033\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32mC:\\Users\\Shachi Shah\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1050\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1051\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1052\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1053\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1054\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[64,512,512,64]\n\t [[Node: b1c1/Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](_recv_input_data/X_0/_101, b1c1/W/read)]]\n\t [[Node: Adam/clip_by_global_norm/Adam/clip_by_global_norm/_8/_205 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_887_Adam/clip_by_global_norm/Adam/clip_by_global_norm/_8\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'b1c1/Conv2D', defined at:\n  File \"C:\\Users\\Shachi Shah\\Anaconda3\\lib\\runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\Shachi Shah\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Shachi Shah\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Shachi Shah\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\Shachi Shah\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Users\\Shachi Shah\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\Shachi Shah\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\Shachi Shah\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Shachi Shah\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\Shachi Shah\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\Shachi Shah\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\Shachi Shah\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Shachi Shah\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\Shachi Shah\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\Shachi Shah\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\Shachi Shah\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Shachi Shah\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\Shachi Shah\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\Shachi Shah\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\Shachi Shah\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-28-9fcb33de5cb3>\", line 10, in <module>\n    x = conv_2d(net, 64, 3, activation='relu', name='b1c1')\n  File \"C:\\Users\\Shachi Shah\\Anaconda3\\lib\\site-packages\\tflearn\\layers\\conv.py\", line 99, in conv_2d\n    inference = tf.nn.conv2d(incoming, W, strides, padding)\n  File \"C:\\Users\\Shachi Shah\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 403, in conv2d\n    data_format=data_format, name=name)\n  File \"C:\\Users\\Shachi Shah\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"C:\\Users\\Shachi Shah\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"C:\\Users\\Shachi Shah\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[64,512,512,64]\n\t [[Node: b1c1/Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](_recv_input_data/X_0/_101, b1c1/W/read)]]\n\t [[Node: Adam/clip_by_global_norm/Adam/clip_by_global_norm/_8/_205 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_887_Adam/clip_by_global_norm/Adam/clip_by_global_norm/_8\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "model.fit({'input_data':X}, {'ofuse':Y}, n_epoch=10, validation_set=0.1,\n",
    "          show_metric=True, snapshot_step=200, snapshot_epoch=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
