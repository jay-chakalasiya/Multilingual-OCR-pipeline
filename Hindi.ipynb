{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-edb4c1d649c0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Inputs/HE set/128-20-NR-NY-NF-0.pickle'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'get_data' is not defined"
     ]
    }
   ],
   "source": [
    "get_data('Inputs/HE set/128-20-NR-NY-NF-0.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(192, 64)\n"
     ]
    }
   ],
   "source": [
    "img = k['X'][0][:,:,0]\n",
    "print(img.shape)\n",
    "img = img.reshape((64,192))\n",
    "import numpy as np\n",
    "import cv2\n",
    "cv2.namedWindow('image', cv2.WINDOW_NORMAL)\n",
    "cv2.imshow('image',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mono_word = []\n",
    "bi_words = []\n",
    "chars = []\n",
    "files = os.listdir('Inputs/hin_corp_unicode')\n",
    "for file in files:\n",
    "    print(file)\n",
    "    import codecs\n",
    "    f = codecs.open('Inputs/hin_corp_unicode/'+file, encoding='utf-8')\n",
    "    for line in f:\n",
    "        line = line.strip('\\n').strip('\\r').strip(' ')\n",
    "        if line != '':\n",
    "            words = line.split(' ')\n",
    "            for word in words:\n",
    "                if word not in mono_word:\n",
    "                    mono_word.append(word)\n",
    "                    for char in list(word):\n",
    "                        if char not in chars:\n",
    "                            chars.append(char)\n",
    "            for i in range(len(words)-1):\n",
    "                string = words[i]+' '+words[i+1]\n",
    "                if string not in bi_words:\n",
    "                    bi_words.append(string)\n",
    "dict = {'bi-grams':np.array(bi_words), 'mono-grams':np.array(mono_word), 'symbols':np.array(symbols)}\n",
    "import pickle\n",
    "pickle.dump( dict, open( \"Inputs/words_hindi.pickle\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "str=''\n",
    "x_l = ['0','1','2','3','4','5','6','7']\n",
    "y_l = ['0','1','2','3','4','5','6','7','8','9','A','B','C','D','E','F']\n",
    "for x in x_l:\n",
    "    for y in y_l:\n",
    "        str+='u\\'\\\\u09'+x+y+'\\','\n",
    "#k = 'u\\'\\\\u09'+x+y+'\\','"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols = [u'\\u0900',u'\\u0901',u'\\u0902',u'\\u0903',u'\\u0904',u'\\u0905',u'\\u0906',u'\\u0907',u'\\u0908',u'\\u0909',u'\\u090A',u'\\u090B',u'\\u090C',u'\\u090D',u'\\u090E',u'\\u090F',u'\\u0910',u'\\u0911',u'\\u0912',u'\\u0913',u'\\u0914',u'\\u0915',u'\\u0916',u'\\u0917',u'\\u0918',u'\\u0919',u'\\u091A',u'\\u091B',u'\\u091C',u'\\u091D',u'\\u091E',u'\\u091F',u'\\u0920',u'\\u0921',u'\\u0922',u'\\u0923',u'\\u0924',u'\\u0925',u'\\u0926',u'\\u0927',u'\\u0928',u'\\u0929',u'\\u092A',u'\\u092B',u'\\u092C',u'\\u092D',u'\\u092E',u'\\u092F',u'\\u0930',u'\\u0931',u'\\u0932',u'\\u0933',u'\\u0934',u'\\u0935',u'\\u0936',u'\\u0937',u'\\u0938',u'\\u0939',u'\\u093A',u'\\u093B',u'\\u093C',u'\\u093D',u'\\u093E',u'\\u093F',u'\\u0940',u'\\u0941',u'\\u0942',u'\\u0943',u'\\u0944',u'\\u0945',u'\\u0946',u'\\u0947',u'\\u0948',u'\\u0949',u'\\u094A',u'\\u094B',u'\\u094C',u'\\u094D',u'\\u094E',u'\\u094F',u'\\u0950',u'\\u0951',u'\\u0952',u'\\u0953',u'\\u0954',u'\\u0955',u'\\u0956',u'\\u0957',u'\\u0958',u'\\u0959',u'\\u095A',u'\\u095B',u'\\u095C',u'\\u095D',u'\\u095E',u'\\u095F',u'\\u0960',u'\\u0961',u'\\u0962',u'\\u0963',u'\\u0964',u'\\u0965',u'\\u0966',u'\\u0967',u'\\u0968',u'\\u0969',u'\\u096A',u'\\u096B',u'\\u096C',u'\\u096D',u'\\u096E',u'\\u096F',u'\\u0970',u'\\u0971',u'\\u0972',u'\\u0973',u'\\u0974',u'\\u0975',u'\\u0976',u'\\u0977',u'\\u0978',u'\\u0979',u'\\u097A',u'\\u097B',u'\\u097C',u'\\u097D',u'\\u097E',u'\\u097F','!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-','.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':',';', '<', '=', '>', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G','H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T','U', 'V', 'W', 'X', 'Y', 'Z', '[', '\\\\', ']', '^', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '{', '|', '}', '~', '£', 'Â']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras.callbacks\n",
    "#-------------------------------------Read Pickle data---------------------------------------------------\n",
    "def get_data(file):\n",
    "    import pickle\n",
    "    with open(file,'rb') as f:\n",
    "        return pickle.load(f)\n",
    "#-------------------------------------Process the labels-----------------------------------------------\n",
    "def process_source_strings(strings_array):\n",
    "    source_strings=[]\n",
    "    for string in strings_array:\n",
    "        word = string.split('_')[1]\n",
    "        source_strings.append(word)\n",
    "    return source_strings\n",
    "\n",
    "def shuffle_mats_or_lists(matrix_list, stop_ind=None):\n",
    "        import numpy as np\n",
    "        ret = []\n",
    "\n",
    "        assert all([len(i) == len(matrix_list[0]) for i in matrix_list])    # All array length must be equal\n",
    "        len_val = len(matrix_list[0])\n",
    "\n",
    "        if stop_ind is None:\n",
    "            stop_ind = len_val\n",
    "        assert stop_ind <= len_val\n",
    "\n",
    "        a = list(range(stop_ind))\n",
    "        np.random.shuffle(a)\n",
    "\n",
    "        a += list(range(stop_ind, len_val))\n",
    "\n",
    "        for mat in matrix_list:\n",
    "            if isinstance(mat, np.ndarray):\n",
    "                ret.append(mat[a])\n",
    "            elif isinstance(mat, list):\n",
    "                ret.append([mat[i] for i in a])\n",
    "            else:\n",
    "                raise TypeError('`shuffle_mats_or_lists` only supports numpy.array and list objects.')\n",
    "\n",
    "        return ret\n",
    "    \n",
    "def text_to_labels(symbol_string, text):\n",
    "        ret = []\n",
    "\n",
    "        for char in text:\n",
    "            ret.append(symbol_string.find(char))\n",
    "\n",
    "        return ret\n",
    "\n",
    "def labels_to_text(labels):\n",
    "    ret = []\n",
    "\n",
    "    for c in labels:\n",
    "        if c == len(symbol_string):               # CTC Blank\n",
    "            ret.append(\"\")\n",
    "        else:\n",
    "            ret.append(symbol_string[c])\n",
    "\n",
    "    return \"\".join(ret)\n",
    "\n",
    "def is_valid_string(temp_str):\n",
    "    for char in temp_str:\n",
    "        if char not in symbol_list:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def paint_it(text, w, h, input_path, ratio, rotate=False, y_traslation=False, multi_fonts=False, script='H'):\n",
    "\n",
    "    from PIL import Image, ImageDraw, ImageFont\n",
    "    from numpy import asarray\n",
    "    import numpy as np\n",
    "    from scipy import ndimage\n",
    "    import os\n",
    "    import math\n",
    "    \n",
    "    #ratio = w/h\n",
    "    #-------------------Canvas-----------------\n",
    "    R = np.random.randint(0,255)\n",
    "    G = np.random.randint(0,255)\n",
    "    B = np.random.randint(0,255)\n",
    "    base_color = int(0.21*R+0.72*G+0.07*B)\n",
    "    surface = Image.new(\"RGBA\", (w, h), color=(R,G,B,255))\n",
    "\n",
    "    trig=0\n",
    "    while trig==0:\n",
    "    \n",
    "        #-------------------Font Selection--------------------------------------\n",
    "\n",
    "        if script=='E':\n",
    "            path = input_path+'/fonts'\n",
    "            final_text=text\n",
    "        elif script=='H':\n",
    "            path = input_path+'/Hindi_fonts/UTF'\n",
    "            length_text = len(text)\n",
    "            final_text = ''\n",
    "            i=0\n",
    "            while i<length_text-1:\n",
    "                if text[i+1]==u'\\u093F':\n",
    "                    final_text+=u'\\u093F'\n",
    "                    final_text+=text[i]\n",
    "                    i+=2\n",
    "                else:\n",
    "                    final_text+=text[i]\n",
    "                    i+=1\n",
    "            if len(final_text)<len(text):\n",
    "                final_text+=text[-1]\n",
    "        elif script=='G':\n",
    "            path = input_path+'/Gujarati_fonts'\n",
    "            finak_text=text\n",
    "\n",
    "        if multi_fonts:\n",
    "            font_selected = np.random.choice(os.listdir(path))\n",
    "        else:\n",
    "            font_selected = np.random.choice(os.listdir(path)[0:3])\n",
    "\n",
    "        #-------------------Rotation Angle--------------------------------------------\n",
    "        rotation_angle=0\n",
    "        if rotate:\n",
    "            rotation_angle = np.random.randint(50)-25\n",
    "        if rotation_angle<=0:\n",
    "            rad = (rotation_angle+360)*3.14/180\n",
    "        else:\n",
    "            rad = rotation_angle*3.14/180\n",
    "\n",
    "\n",
    "        #-----------------------Font Size---------------------------------------------------\n",
    "\n",
    "        font_size = 1\n",
    "        f = ImageFont.truetype(path+'/'+font_selected, font_size)\n",
    "        text_width, text_height = f.getsize(text)\n",
    "        if text_height==0:\n",
    "            text_ratio=90\n",
    "        else:\n",
    "            text_ratio = text_width/text_height\n",
    "\n",
    "        if text_ratio>=ratio:         #text width is more\n",
    "            subjected_width = text_width*abs(math.cos(rad))+text_height*abs(math.sin(rad))\n",
    "            while subjected_width <= w-5:\n",
    "                font_size+=1\n",
    "                f = ImageFont.truetype(path+'/'+font_selected, font_size)\n",
    "                text_width, text_height = f.getsize(text)\n",
    "                subjected_width = text_width*abs(math.cos(rad))+text_height*abs(math.sin(rad))\n",
    "            font_size-=1\n",
    "\n",
    "        else:                         # text height is more\n",
    "            subjected_height = text_height*abs(math.cos(rad))+text_width*abs(math.sin(rad))\n",
    "            while subjected_height <= h-5:\n",
    "                font_size+=1\n",
    "                f = ImageFont.truetype(path+'/'+font_selected, font_size)\n",
    "                text_width, text_height = f.getsize(text)\n",
    "                subjected_height = text_height*abs(math.cos(rad))+text_width*abs(math.sin(rad))\n",
    "            font_size-=1\n",
    "\n",
    "        # ----------------------------- height and width after rotation ---------------------------------\n",
    "        f = ImageFont.truetype(path+'/'+font_selected, font_size)\n",
    "        text_width, text_height = f.getsize(text)\n",
    "        final_height = text_height*abs(math.cos(rad))+text_width*abs(math.sin(rad))\n",
    "        final_width = text_width*abs(math.cos(rad))+text_height*abs(math.sin(rad))\n",
    "        \n",
    "        \n",
    "        if final_width<w-1 and final_height<h-1:\n",
    "            trig=1\n",
    "            \n",
    "    #------------------------------X-Y Trasnpose------------------------------------------------\n",
    "    max_shift_x = w-final_width\n",
    "    max_shift_y = h-final_height\n",
    "    \n",
    "    \n",
    "    top_left_x = np.random.randint(0, int(max_shift_x))\n",
    "    \n",
    "    if y_traslation:\n",
    "        top_left_y = np.random.randint(0, int(max_shift_y))\n",
    "    else:\n",
    "        top_left_y = 2    \n",
    "        \n",
    "    \n",
    "    #--------------------------------Upper Canvas--------------------------------------------\n",
    "\n",
    "    text_canvas = Image.new(\"RGBA\", (int(final_width), int(final_height)), color=(R,G,B,255))\n",
    "    draw = ImageDraw.Draw(text_canvas)\n",
    "    \n",
    "    difference = 0\n",
    "    while difference==0:\n",
    "        R_ = np.random.randint(0,255)\n",
    "        G_ = np.random.randint(0,255)\n",
    "        B_ = np.random.randint(0,255)\n",
    "        font_color = int(0.21*R_+0.72*G_+0.07*B_)\n",
    "        if abs(font_color-base_color)>=127:\n",
    "            difference=1\n",
    "    \n",
    "    draw.text((0, 0), final_text, font=f, fill=(R_,G_,B_))\n",
    "    \n",
    "    #-------------------------------Text Rotation----------------------------------------------\n",
    "\n",
    "    if rotate:                                                                   \n",
    "        text_canvas = text_canvas.rotate(rotation_angle, expand=1)\n",
    "  \n",
    "    # -----------------------------Paste Canvas---------------------------------------------------\n",
    "\n",
    "    sx, sy = text_canvas.size\n",
    "    surface.paste(text_canvas, (top_left_x, top_left_y, top_left_x+sx, top_left_y+sy), text_canvas)\n",
    "    \n",
    "    #-----------------------------Binary of Image-----------------------------------------------\n",
    "\n",
    "    surface = asarray(surface.convert('L'))\n",
    "    surface = surface.astype(np.float32)/255\n",
    "\n",
    "    #------------------------------Gaussian Noise------------------------------------------------\n",
    "\n",
    "    severity = np.random.uniform(0, 0.6)\n",
    "    blur = ndimage.gaussian_filter(np.random.randn(*surface.shape) * severity, 1)                        \n",
    "    surface = (surface + blur)\n",
    "    surface[surface > 1] = 1\n",
    "    surface[surface <= 0] = 0\n",
    "    \n",
    "    #-------------------------------Inverse of image------------------------------------------------\n",
    "\n",
    "    k = np.random.choice([0,1])\n",
    "    if k==1:\n",
    "        surface = 1-surface\n",
    "\n",
    "    return np.array([surface])\n",
    "\n",
    "class Visuals_manual(keras.callbacks.Callback):\n",
    "\n",
    "    def __init__(self, run_name, test_func, inputs, outputs, num_display_words=8):\n",
    "        \n",
    "        import os\n",
    "        self.test_func = test_func\n",
    "        \n",
    "        self.output_dir = os.path.join(OUTPUT_DIR, run_name)\n",
    "        if not os.path.exists(self.output_dir):\n",
    "            os.makedirs(self.output_dir)\n",
    "            \n",
    "        self.inputs = inputs\n",
    "        self.outputs = outputs\n",
    "        self.num_display_words = num_display_words\n",
    "       \n",
    "\n",
    "    def show_edit_distance(self, num):\n",
    "        import editdistance\n",
    "        num_left = num\n",
    "        mean_norm_ed = 0.0\n",
    "        mean_ed = 0.0\n",
    "        word_err = 0\n",
    "        word_total = 0\n",
    "        char_err = 0\n",
    "        char_total = 0\n",
    "        batch_num=1\n",
    "        \n",
    "        while num_left > 0:\n",
    "            word_batch = self.inputs[(batch_num-1)*32:batch_num*32]\n",
    "            num_proc = min(word_batch['inputs'].shape[0], num_left)\n",
    "            word_total+=num_proc\n",
    "            decoded_res = decode_batch(self.test_func, word_batch['inputs'][0:num_proc])\n",
    "            \n",
    "            for j in range(num_proc):\n",
    "                char_total+=len(decoded_res[j])\n",
    "                if decoded_res[j] != word_batch['source_str'][j]:\n",
    "                    word_err+=1\n",
    "                    k=0\n",
    "                    while k<min(len(decoded_res[j]),len(word_batch['source_str'][j])):\n",
    "                        if decoded_res[j][k] != word_batch['source_str'][j][k]:\n",
    "                            char_err+=1\n",
    "                        k+=1\n",
    "                edit_dist = editdistance.eval(decoded_res[j], word_batch['source_str'][j])\n",
    "                mean_ed += float(edit_dist)\n",
    "                mean_norm_ed += float(edit_dist)\n",
    "                #mean_norm_ed += float(edit_dist)  /len(word_batch['source_str'][j])\n",
    "            batch_num+=1\n",
    "            num_left -= num_proc\n",
    "            \n",
    "        mean_norm_ed = mean_norm_ed / num\n",
    "        mean_ed = mean_ed / num\n",
    "        print('\\nOut of %d samples:  Mean edit distance: %.3f Mean normalized edit distance: %0.3f' % (num, mean_ed, mean_norm_ed))\n",
    "        print('char err = ',char_err,'/',char_total,'  -------  word err = ',word_err,'/',word_total)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        import os\n",
    "        import pylab\n",
    "        from keras import backend as K\n",
    "        \n",
    "        self.model.save_weights(os.path.join(self.output_dir, 'weights%02d.h5' % (epoch)))\n",
    "        #self.show_edit_distance(256)\n",
    "        \n",
    "        word_batch = self.inputs\n",
    "        res = decode_batch(self.test_func, word_batch['inputs'][0:self.num_display_words])\n",
    "        \n",
    "        if word_batch['inputs'][0].shape[0] <= 256:\n",
    "            cols = 2\n",
    "        else:\n",
    "            cols = 1\n",
    "            \n",
    "        for i in range(self.num_display_words):\n",
    "            pylab.subplot(self.num_display_words // cols, cols, i + 1)\n",
    "            \n",
    "            if K.image_data_format() == 'channels_first':\n",
    "                the_input = word_batch['inputs'][i, 0, :, :]\n",
    "            else:\n",
    "                the_input = word_batch['inputs'][i, :, :, 0]\n",
    "                \n",
    "    #------------------------------------------------for new image set----------------------------------------------------\n",
    "            the_input = np.flip(the_input,0)\n",
    "    #---------------------------------------------------------------------------------------------------------------------\n",
    "            pylab.imshow(the_input.T, cmap='Greys_r')\n",
    "            pylab.xlabel('Truth = \\'%s\\'\\nDecoded = \\'%s\\'' % (word_batch['source_str'][i], res[i]))\n",
    "            print('Real = \\'%s --  Pred = \\'%s\\'' % (word_batch['source_str'][i], res[i]))\n",
    "        fig = pylab.gcf()\n",
    "        fig.set_size_inches(10, 13)\n",
    "        pylab.savefig(os.path.join(self.output_dir, 'e%02d.png' % (epoch)))\n",
    "        pylab.close()\n",
    "        \n",
    "class Visuals(keras.callbacks.Callback):\n",
    "\n",
    "    def __init__(self, run_name, test_func, text_img_gen, num_display_words=8):\n",
    "        \n",
    "        import os\n",
    "        self.test_func = test_func\n",
    "        \n",
    "        self.output_dir = os.path.join(OUTPUT_DIR, run_name)\n",
    "        if not os.path.exists(self.output_dir):\n",
    "            os.makedirs(self.output_dir)\n",
    "            \n",
    "        self.text_img_gen = text_img_gen\n",
    "        self.num_display_words = num_display_words\n",
    "       \n",
    "\n",
    "    def show_edit_distance(self, num):\n",
    "        import editdistance\n",
    "        num_left = num\n",
    "        mean_norm_ed = 0.0\n",
    "        mean_ed = 0.0\n",
    "        word_err = 0\n",
    "        word_total = 0\n",
    "        char_err = 0\n",
    "        char_total = 0\n",
    "        \n",
    "        while num_left > 0:\n",
    "            word_batch = next(self.text_img_gen)[0]\n",
    "            num_proc = min(word_batch['inputs'].shape[0], num_left)\n",
    "            word_total+=num_proc\n",
    "            decoded_res = decode_batch(self.test_func, word_batch['inputs'][0:num_proc])\n",
    "            \n",
    "            for j in range(num_proc):\n",
    "                char_total+=len(decoded_res[j])\n",
    "                if decoded_res[j] != word_batch['source_str'][j]:\n",
    "                    word_err+=1\n",
    "                    k=0\n",
    "                    while k<min(len(decoded_res[j]),len(word_batch['source_str'][j])):\n",
    "                        if decoded_res[j][k] != word_batch['source_str'][j][k]:\n",
    "                            char_err+=1\n",
    "                        k+=1\n",
    "                edit_dist = editdistance.eval(decoded_res[j], word_batch['source_str'][j])\n",
    "                mean_ed += float(edit_dist)\n",
    "                mean_norm_ed += float(edit_dist)\n",
    "                #mean_norm_ed += float(edit_dist)  /len(word_batch['source_str'][j])\n",
    "                \n",
    "            num_left -= num_proc\n",
    "            \n",
    "        mean_norm_ed = mean_norm_ed / num\n",
    "        mean_ed = mean_ed / num\n",
    "        print('\\nOut of %d samples:  Mean edit distance: %.3f Mean normalized edit distance: %0.3f' % (num, mean_ed, mean_norm_ed))\n",
    "        print('char err = ',char_err,'/',char_total,'  -------  word err = ',word_err,'/',word_total)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        import os\n",
    "        import pylab\n",
    "        from keras import backend as K\n",
    "        \n",
    "        self.model.save_weights(os.path.join(self.output_dir, 'weights%02d.h5' % (epoch)))\n",
    "        self.show_edit_distance(256)\n",
    "        \n",
    "        word_batch = next(self.text_img_gen)[0]\n",
    "        res = decode_batch(self.test_func, word_batch['inputs'][0:self.num_display_words])\n",
    "        \n",
    "        if word_batch['inputs'][0].shape[0] <= 256:\n",
    "            cols = 2\n",
    "        else:\n",
    "            cols = 1\n",
    "            \n",
    "        for i in range(self.num_display_words):\n",
    "            pylab.subplot(self.num_display_words // cols, cols, i + 1)\n",
    "            \n",
    "            if K.image_data_format() == 'channels_first':\n",
    "                the_input = word_batch['inputs'][i, 0, :, :]\n",
    "            else:\n",
    "                the_input = word_batch['inputs'][i, :, :, 0]\n",
    "                \n",
    "            pylab.imshow(the_input.T, cmap='Greys_r')\n",
    "            pylab.xlabel('Truth = \\'%s\\'\\nDecoded = \\'%s\\'' % (word_batch['source_str'][i], res[i]))\n",
    "            print('Real = \\'%s --  Pred = \\'%s\\'' % (word_batch['source_str'][i], res[i]))\n",
    "        fig = pylab.gcf()\n",
    "        fig.set_size_inches(10, 13)\n",
    "        pylab.savefig(os.path.join(self.output_dir, 'e%02d.png' % (epoch)))\n",
    "        pylab.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Text_Image_Feed_Generator(keras.callbacks.Callback):\n",
    "    \n",
    "#------------------------------------------------------Initialize Class-----------------------------------------------------\n",
    "    \n",
    "    def __init__(self, symbol_string, input_path, num_words, validation_words, mini_batch_size, image_width, image_height, shrink_factor, absolute_length=48):\n",
    "        \n",
    "        self.input_path = input_path\n",
    "        self.symbol_string = symbol_string\n",
    "        self.symbol_list = list(symbol_string)\n",
    "        \n",
    "        self.num_words = num_words\n",
    "        self.validation_words = validation_words\n",
    "        self.training_words = self.num_words-self.validation_words\n",
    "        self.mini_batch_size = mini_batch_size\n",
    "        \n",
    "        self.image_width = image_width\n",
    "        self.image_height = image_height\n",
    "        self.shrink_factor = shrink_factor\n",
    "        \n",
    "        self.output_size = len(self.symbol_string)+1\n",
    "        self.blank_label = len(self.symbol_string)\n",
    "        \n",
    "        self.max_len = self.max_words()\n",
    "        self.min_len = 3\n",
    "        \n",
    "        self.absolute_length = absolute_length\n",
    "    \n",
    "#------------------------------------------------------Maximum length of string------------------------------------------------    \n",
    "    \n",
    "    def max_words(self):\n",
    "        \n",
    "        #import os\n",
    "        #from PIL import ImageFont\n",
    "        #fonts = os.listdir(self.input_path+'/Hindi_fonts/UTF')\n",
    "        \n",
    "        #max_width=0\n",
    "        #selected_font=''\n",
    "        '''for font in fonts:\n",
    "            f = ImageFont.truetype(self.input_path+'/Hindi_fonts/UTF/'+font, int(self.image_height*0.4))\n",
    "            w,h = f.getsize('Wii')\n",
    "            if w>max_width:\n",
    "                max_width=w\n",
    "            selected_font=font\n",
    "        i=0\n",
    "        temp = 0\n",
    "        f = ImageFont.truetype(self.input_path+'/Hindi_fonts/UTF/'+selected_font, int(self.image_height*0.4))\n",
    "        while temp<int(self.image_width*1.6):\n",
    "            temp,_ = f.getsize('WA'*i)\n",
    "            i+=1'''\n",
    "            \n",
    "        return np.random.randint((self.image_width//16)-(self.image_width//32),self.image_width//16)\n",
    "\n",
    "#---------------------------------------------------Generate Word list ---------------------------------------------------\n",
    "\n",
    "    def generate_word_list(self):\n",
    "        import os\n",
    "        import codecs\n",
    "        import pickle\n",
    "\n",
    "        self.string_list = []\n",
    "        \n",
    "        self.Y_data = np.ones([self.num_words, self.absolute_length]) * -1    # Maximum threshold of words possible\n",
    "        self.X_text = []                                                      # Actual Text Data\n",
    "        self.Y_len = [0] * self.num_words                                     # Actual Length of Labels\n",
    "        \n",
    "        \n",
    "        \n",
    "        while len(self.string_list) < self.num_words:\n",
    "            import pickle\n",
    "            pickle_in = open(self.input_path+'/words_hindi.pickle','rb')\n",
    "            data = pickle.load(pickle_in)\n",
    "            \n",
    "            mono = data['mono-grams']\n",
    "            bi = data['bi-grams']\n",
    "            np.random.shuffle(mono)\n",
    "            np.random.shuffle(bi)\n",
    "\n",
    "            for string in mono:\n",
    "                if self.num_words<32000:\n",
    "                    if len(self.string_list) < self.num_words:                        \n",
    "                        if len(string) <= self.max_len and len(string)>=self.min_len: \n",
    "                            self.string_list.append(string)\n",
    "                if self.num_words>32000:\n",
    "                    if len(self.string_list) < 20000:                        \n",
    "                        if len(string) <= self.max_len and len(string)>=self.min_len: \n",
    "                            self.string_list.append(string)\n",
    "            print(len(self.string_list),' mono-grams-pooled')\n",
    "            for string in bi:\n",
    "                if len(self.string_list) < self.num_words:\n",
    "                    if len(string) <= self.max_len and len(string)>=self.min_len: \n",
    "                        self.string_list.append(string)\n",
    "            print(len(self.string_list),' bi-grams-pooled')  \n",
    "            if len(self.string_list) < self.num_words:\n",
    "                print(len(self.string_list), ' Words pulled, iterating again to achieve total of ', self.num_words)\n",
    "\n",
    "        for i, word in enumerate(self.string_list):\n",
    "            self.Y_len[i] = len(word)\n",
    "            self.Y_data[i, 0:len(word)] = text_to_labels(self.symbol_string,word)\n",
    "            self.X_text.append(word)\n",
    "            \n",
    "        self.Y_len = np.expand_dims(np.array(self.Y_len), 1)                             #shape=(self.Y_len,1)\n",
    "         \n",
    "        self.current_val_index = self.training_words\n",
    "        self.current_train_index = 0\n",
    "        \n",
    "#-----------------------------------------------------batch Maker----------------------------------------------------\n",
    "\n",
    "    def get_batch(self, start_index, size, isTrain):\n",
    "        \n",
    "        from keras import backend as K\n",
    "        \n",
    "        if K.image_data_format() == 'channels_first':\n",
    "            X_data = np.ones([size, 1, self.image_width, self.image_height])\n",
    "        else:\n",
    "            X_data = np.ones([size, self.image_width, self.image_height, 1])\n",
    "            \n",
    "\n",
    "        labels = np.ones([size, self.absolute_length])\n",
    "        \n",
    "        input_length = np.zeros([size, 1])\n",
    "        label_length = np.zeros([size, 1])\n",
    "        \n",
    "        source_strings = []\n",
    "        \n",
    "        for i in range(size):\n",
    "            \n",
    "            if isTrain and i > size - 4:                                                 # some random blank data\n",
    "                \n",
    "                if K.image_data_format() == 'channels_first':\n",
    "                    X_data[i, 0, 0:self.image_width, :] = self.make_img('')[0, :, :].T\n",
    "                else:\n",
    "                    X_data[i, 0:self.image_width, :, 0] = self.make_img('',)[0, :, :].T\n",
    "                    \n",
    "                labels[i, 0] = self.blank_label\n",
    "                \n",
    "                label_length[i] = 1\n",
    "                source_strings.append('')\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                if K.image_data_format() == 'channels_first':\n",
    "                    X_data[i, 0, 0:self.image_width, :] = self.make_img(self.X_text[start_index + i])[0, :, :].T\n",
    "                else:\n",
    "                    X_data[i, 0:self.image_width, :, 0] = self.make_img(self.X_text[start_index + i])[0, :, :].T\n",
    "                    \n",
    "                labels[i, :] = self.Y_data[start_index + i]\n",
    "                label_length[i] = self.Y_len[start_index + i]\n",
    "                source_strings.append(self.X_text[start_index + i])\n",
    "                \n",
    "            input_length[i] = (self.image_width // self.shrink_factor) - 2        # same for all inputs\n",
    "                \n",
    "        inputs = {'inputs': X_data, 'labels': labels, 'input_length': input_length, 'label_length': label_length, 'source_str': source_strings}\n",
    "        outputs = {'ctc': np.zeros([size])}  # dummy\n",
    "        return (inputs, outputs)\n",
    "    \n",
    "#-----------------------------------------------------------Training & Testing Batch-----------------------------------------\n",
    "        \n",
    "    def next_train(self):\n",
    "        while 1:\n",
    "            ret = self.get_batch(self.current_train_index, self.mini_batch_size, isTrain=True)\n",
    "            self.current_train_index += self.mini_batch_size\n",
    "            \n",
    "            if self.current_train_index >= self.training_words:\n",
    "                self.current_train_index = self.current_train_index % 32\n",
    "                (self.X_text, self.Y_data, self.Y_len) = shuffle_mats_or_lists([self.X_text, self.Y_data, self.Y_len], self.training_words)\n",
    "                \n",
    "            yield ret\n",
    "            \n",
    "    def next_val(self):\n",
    "        while 1:\n",
    "            \n",
    "            ret = self.get_batch(self.current_val_index, self.mini_batch_size, isTrain=False)\n",
    "            self.current_val_index += self.mini_batch_size\n",
    "            \n",
    "            if self.current_val_index >= self.num_words:\n",
    "                self.current_val_index = self.training_words + self.current_val_index % 32\n",
    "                \n",
    "            yield ret\n",
    "            \n",
    "#--------------------------------------------------------Callbacks------------------------------------------------------------\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.generate_word_list()\n",
    "        self.make_img = lambda text: paint_it(text, self.image_width, self.image_height, self.input_path, self.image_width//self.image_height, rotate=False, y_traslation=False, multi_fonts=False)\n",
    "        \n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        (self.X_text, self.Y_data, self.Y_len) = shuffle_mats_or_lists([self.X_text, self.Y_data, self.Y_len])\n",
    "        if 3 <= epoch < 6:\n",
    "            self.make_img = lambda text: paint_it(text, self.image_width, self.image_height, self.input_path, self.image_width//self.image_height, rotate=False, y_traslation=True, multi_fonts=False, )\n",
    "        elif 6 <= epoch < 9:\n",
    "            self.make_img = lambda text: paint_it(text, self.image_width, self.image_height, self.input_path, self.image_width//self.image_height, rotate=False, y_traslation=True, multi_fonts=True)\n",
    "        elif epoch >= 9:        \n",
    "            self.make_img = lambda text: paint_it(text, self.image_width, self.image_height, self.input_path, self.image_width//self.image_height, rotate=True, y_traslation=True, multi_fonts=True)        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x_y(file, image_width, shrink_factor, absolute_length=32):\n",
    "    import numpy as np\n",
    "    data = get_data(file)\n",
    "    size = len(data['X'])\n",
    "    \n",
    "    X = data['X']/255\n",
    "    source_strings = data['Y']#process_source_strings(data['Y'])\n",
    "    \n",
    "    input_length = np.zeros([size, 1])\n",
    "    label_length = np.zeros([size, 1])\n",
    "    labels = np.ones([size, absolute_length]) * -1\n",
    "    \n",
    "    for i, word in enumerate(source_strings):\n",
    "        label_length[i] = len(word)\n",
    "        labels[i, 0:len(word)] = text_to_labels(symbol_string, word)\n",
    "        input_length[i] = (image_width // (shrink_factor)) - 2\n",
    "                \n",
    "    inputs = {'inputs': X, 'labels': labels, 'input_length': input_length, 'label_length': label_length, 'source_str': source_strings}\n",
    "    outputs = {'ctc': np.zeros([size])}\n",
    "    return inputs, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctc_lambda_func(args):\n",
    "    from keras import backend as K\n",
    "    \n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    #print(y_pred)\n",
    "    y_pred = y_pred[:, 2:, :]\n",
    "    \n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    "\n",
    "\n",
    "# For a real OCR application, this should be beam search with a dictionary\n",
    "# and language model.  For this example, best path is sufficient.\n",
    "\n",
    "def decode_batch(test_func, word_batch):\n",
    "    import itertools\n",
    "    out = test_func([word_batch])[0]\n",
    "    ret = []\n",
    "    for j in range(out.shape[0]):\n",
    "        out_best = list(np.argmax(out[j, 2:], 1))\n",
    "        print(list(labels_to_text(out_best)))\n",
    "        out_best = [k for k, g in itertools.groupby(out_best)]\n",
    "        outstr = labels_to_text(out_best)\n",
    "        ret.append(outstr)\n",
    "    return ret\n",
    "\n",
    "def fire(x, pipe, out):\n",
    "    from keras.layers.convolutional import Conv2D\n",
    "    from keras.layers.merge import add, concatenate\n",
    "    x = Conv2D(pipe, (1,1), padding='same', activation='relu', kernel_initializer='he_normal')(x)# name=name+'-0-1x1'\n",
    "    y_ = Conv2D(out//2, (1,1), padding='same', activation='relu', kernel_initializer='he_normal')(x)#, name=name+'-1-1x1'\n",
    "    y__ = Conv2D(out//2, (3,3), padding='same', activation='relu', kernel_initializer='he_normal')(x)#, name=name+'-1-3x3'\n",
    "    y = concatenate([y_, y__],axis=-1)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model_name, start_epoch, end_epoch, image_width, image_height=64, num_samples=16000, split_ratio=0.1, mini_batch_size=32, training_method='Generator', input_dir='Inputs', file_name=None):# Method = Generator/Manual\n",
    "    from keras import backend as K\n",
    "    from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "    from keras.layers import Input, Dense, Activation, BatchNormalization\n",
    "    from keras.layers import Reshape, Lambda, Dropout\n",
    "    from keras.layers.merge import add, concatenate\n",
    "    from keras.models import Model\n",
    "    from keras.layers.recurrent import GRU, LSTM\n",
    "    from keras.optimizers import SGD, Adam\n",
    "    from keras.utils.data_utils import get_file\n",
    "    from keras.preprocessing import image\n",
    "    import keras.callbacks\n",
    "    import os\n",
    "    \n",
    "    \n",
    "    # Input Parameters\n",
    "    validation_words = int(num_samples * split_ratio)\n",
    "\n",
    "    # Network parameters\n",
    "                    \n",
    "    stride_size = 2\n",
    "    time_dense_size = 32\n",
    "    rnn_stack = 512\n",
    "    shrink_factor = stride_size**3\n",
    "    \n",
    "    absolute_length=32\n",
    "\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        input_shape = (1, image_width, image_height)\n",
    "    else:\n",
    "        input_shape = (image_width, image_height, 1)\n",
    "    #print(K.image_data_format())\n",
    "    #input_shape = (1, image_width, image_height)\n",
    "\n",
    "#----------------------------------------------------Model-----------------------------------------------------------\n",
    "        \n",
    "    input_data = Input(name='inputs', shape=input_shape, dtype='float32')\n",
    "    \n",
    "    inner0 = Conv2D(64, (3,3), padding='same', activation='relu')(input_data)\n",
    "    inner1 = MaxPooling2D(2)(inner0)\n",
    "    \n",
    "    inner2 = Conv2D(128, (3,3), padding='same', activation='relu')(inner1)\n",
    "    inner3 = MaxPooling2D(2)(inner2)\n",
    "    \n",
    "    inner4 = Conv2D(256, (3,3), padding='same', activation='linear')(inner3)\n",
    "    inner5 = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001)(inner4)\n",
    "    inner6 = Activation('relu')(inner5)\n",
    "    inner7 = Conv2D(256, (3,3), padding='same', activation='relu')(inner6)\n",
    "    inner8 = MaxPooling2D(pool_size=(2, 2), padding='same')(inner7)\n",
    "    \n",
    "    inner9 = Conv2D(512, (3,3), padding='same', activation='linear')(inner8)\n",
    "    inner10 = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001)(inner9)\n",
    "    inner11 = Activation('relu')(inner10)\n",
    "    inner12 = Conv2D(512, (3,3), padding='same', activation='relu')(inner11)\n",
    "    inner13 = MaxPooling2D(pool_size=(2, 2), strides=(1,2), padding='same')(inner12)\n",
    "    \n",
    "    inner14 = Conv2D(512, (2,2), padding='same', activation='linear')(inner13)\n",
    "    inner15 = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001)(inner14)\n",
    "    inner16 = Activation('relu')(inner15)\n",
    "    inner17 = MaxPooling2D(pool_size=(2, 2), strides=(1,2), padding='same')(inner16)\n",
    "    \n",
    "    inner18 = Conv2D(512, (2,2), strides=(1,2), padding='same', activation='linear')(inner17)\n",
    "    inner19 = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001)(inner18)\n",
    "    inner20 = Activation('relu')(inner19)\n",
    "    \n",
    "    rnn_in_dims = (image_width // (shrink_factor), image_height*8 )\n",
    "    \n",
    "    inner21 = Reshape(target_shape=rnn_in_dims, name='reshape')(inner20)\n",
    "\n",
    "    # cuts down input size going into RNN:\n",
    "    #inner21 = Dense(256, activation='relu', name='dense1')(inner21)\n",
    "\n",
    "    lstm_1f = LSTM(rnn_stack//2, return_sequences=True, kernel_initializer='he_normal', name='lstm_1f')(inner21)\n",
    "    lstm_1b = LSTM(rnn_stack//2, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='lstm_1b')(inner21)\n",
    "    lstm1_merged = concatenate([lstm_1f, lstm_1b])\n",
    "    em1 = Dense(256)(lstm1_merged)\n",
    "    \n",
    "    lstm_2f = LSTM(rnn_stack//2, return_sequences=True, kernel_initializer='he_normal', name='lstm_2f')(em1)\n",
    "    lstm_2b = LSTM(rnn_stack//2, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='lstm_2b')(em1)\n",
    "    lstm2_merged = concatenate([lstm_2f, lstm_2b])\n",
    "    em2 = Dense(len(symbol_string)+1)(lstm2_merged)\n",
    "    y_pred = Activation('softmax', name='softmax')(em2)\n",
    "    # transforms RNN output to character activations:\n",
    "    #inner = Dense(len(symbol_string)+1, kernel_initializer='he_normal', name='dense2')(concatenate([lstm_2f, lstm_2b]))\n",
    "    #y_pred = Activation('softmax', name='softmax')(inner)\n",
    "    \n",
    "    Model(inputs=input_data, outputs=y_pred).summary()\n",
    "\n",
    "#---------------------------------------------------Got the outputs-------------------------------------------\n",
    "\n",
    "    labels = Input(name='labels', shape=[absolute_length], dtype='float32')\n",
    "    input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "    label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    "    \n",
    "    # Keras doesn't currently support loss funcs with extra parameters so CTC loss is implemented in a lambda layer\n",
    "    \n",
    "    loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\n",
    "    \n",
    "    #adam = Adam(lr=0.025, beta_1=0.9, beta_2=0.999, epsilon=1e-8, decay=1e-6)\n",
    "    sgd = SGD(lr=0.02, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=5)   # clip the gradients\n",
    "\n",
    "    model = Model(inputs=[input_data, labels, input_length, label_length], outputs=loss_out)\n",
    "\n",
    "    # the loss calc occurs elsewhere, so use a dummy lambda func for the loss\n",
    "    model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=sgd)\n",
    "    \n",
    "    if start_epoch > 0:\n",
    "        weight_file = os.path.join(OUTPUT_DIR, os.path.join(run_name, 'weights%02d.h5' % (start_epoch - 1)))\n",
    "        model.load_weights(weight_file)\n",
    "        \n",
    "        \n",
    "    test_func = K.function([input_data], [y_pred])\n",
    "    \n",
    "    \n",
    "    if training_method=='Generator':\n",
    "        Feed = Text_Image_Feed_Generator(symbol_string, input_dir, num_samples, validation_words, mini_batch_size, image_width, image_height, shrink_factor, absolute_length=absolute_length)\n",
    "        \n",
    "        viz_cb = Visuals(run_name, test_func, Feed.next_val())\n",
    "    \n",
    "    \n",
    "        steps = (num_samples - validation_words) // mini_batch_size\n",
    "        val_steps = validation_words // mini_batch_size\n",
    "\n",
    "        model.fit_generator(generator=Feed.next_train(), steps_per_epoch=steps, initial_epoch=start_epoch, epochs=end_epoch,\n",
    "                            validation_data=Feed.next_val(), validation_steps=val_steps,\n",
    "                            callbacks=[viz_cb, Feed])\n",
    "        \n",
    "    elif training_method=='Manual':\n",
    "        Feed=0\n",
    "        i, o = get_x_y(file_name, image_width, shrink_factor)\n",
    "        i_eval = {'inputs': i['inputs'][:1000], 'labels': i['labels'][:1000], 'input_length': i['input_length'][:1000], 'label_length': i['label_length'][:1000], 'source_str': i['source_str'][:1000]}\n",
    "        o_eval = {'ctc': o['ctc'][:1000]}\n",
    "        \n",
    "        viz = Visuals_manual(run_name, test_func, i_eval, o_eval)\n",
    "          \n",
    "        model.fit(x=i, y=o, batch_size=mini_batch_size, epochs=end_epoch, initial_epoch=start_epoch, callbacks=[viz], \n",
    "                  validation_split=split_ratio, shuffle=True)\n",
    "        \n",
    "    else:\n",
    "        raise ValueError('Please enter valid methon : Generator/Manual')\n",
    "        \n",
    "                               \n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model_name, start_epoch, end_epoch, image_width, image_height=64, num_samples=16000, split_ratio=0.1, mini_batch_size=32, training_method='Generator', input_dir='Inputs', file_name=None):# Method = Generator/Manual\n",
    "    from keras import backend as K\n",
    "    from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "    from keras.layers import Input, Dense, Activation, BatchNormalization\n",
    "    from keras.layers import Reshape, Lambda, Dropout\n",
    "    from keras.layers.merge import add, concatenate\n",
    "    from keras.models import Model\n",
    "    from keras.layers.recurrent import GRU, LSTM\n",
    "    from keras.optimizers import SGD, Adam\n",
    "    from keras.utils.data_utils import get_file\n",
    "    from keras.preprocessing import image\n",
    "    import keras.callbacks\n",
    "    import os\n",
    "    \n",
    "    \n",
    "    # Input Parameters\n",
    "    validation_words = int(num_samples * split_ratio)\n",
    "\n",
    "    # Network parameters\n",
    "                    \n",
    "    stride_size = 2\n",
    "    time_dense_size = 32\n",
    "    rnn_stack = 512\n",
    "    shrink_factor = stride_size**3\n",
    "    \n",
    "    absolute_length=32\n",
    "\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        input_shape = (1, image_width, image_height)\n",
    "    else:\n",
    "        input_shape = (image_width, image_height, 1)\n",
    "    #print(K.image_data_format())\n",
    "    #input_shape = (1, image_width, image_height)\n",
    "\n",
    "#----------------------------------------------------Model-----------------------------------------------------------\n",
    "        \n",
    "    input_data = Input(name='inputs', shape=input_shape, dtype='float32')\n",
    "    \n",
    "    inner0 = Conv2D(64, (3,3), padding='same', activation='relu')(input_data)\n",
    "    inner1 = MaxPooling2D(2)(inner0)\n",
    "    \n",
    "    inner2 = Conv2D(128, (3,3), padding='same', activation='relu')(inner1)\n",
    "    inner3 = MaxPooling2D(2)(inner2)\n",
    "    \n",
    "    inner4 = Conv2D(256, (3,3), padding='same', activation='linear')(inner3)\n",
    "    inner5 = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001)(inner4)\n",
    "    inner6 = Activation('relu')(inner5)\n",
    "    inner7 = Conv2D(256, (3,3), padding='same', activation='relu')(inner6)\n",
    "    inner8 = MaxPooling2D(pool_size=(2, 2), padding='same')(inner7)\n",
    "    \n",
    "    inner9 = Conv2D(512, (3,3), padding='same', activation='linear')(inner8)\n",
    "    inner10 = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001)(inner9)\n",
    "    inner11 = Activation('relu')(inner10)\n",
    "    inner12 = Conv2D(512, (3,3), padding='same', activation='relu')(inner11)\n",
    "    inner13 = MaxPooling2D(pool_size=(2, 2), strides=(1,2), padding='same')(inner12)\n",
    "    \n",
    "    inner14 = Conv2D(512, (2,2), padding='same', activation='linear')(inner13)\n",
    "    inner15 = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001)(inner14)\n",
    "    inner16 = Activation('relu')(inner15)\n",
    "    inner17 = MaxPooling2D(pool_size=(2, 2), strides=(1,2), padding='same')(inner16)\n",
    "    \n",
    "    inner18 = Conv2D(512, (2,2), strides=(1,2), padding='same', activation='linear')(inner17)\n",
    "    inner19 = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001)(inner18)\n",
    "    inner20 = Activation('relu')(inner19)\n",
    "    \n",
    "    rnn_in_dims = (image_width // (shrink_factor), image_height*8 )\n",
    "    \n",
    "    inner21 = Reshape(target_shape=rnn_in_dims, name='reshape')(inner20)\n",
    "\n",
    "    # cuts down input size going into RNN:\n",
    "    #inner21 = Dense(256, activation='relu', name='dense1')(inner21)\n",
    "\n",
    "    lstm_1f = LSTM(rnn_stack, return_sequences=True, kernel_initializer='he_normal', name='lstm_1f')(inner21)\n",
    "    lstm_1b = LSTM(rnn_stack, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='lstm_1b')(inner21)\n",
    "    lstm1_merged = concatenate([lstm_1f, lstm_1b])\n",
    "    em1 = Dense(512)(lstm1_merged)\n",
    "    \n",
    "    lstm_2f = LSTM(rnn_stack, return_sequences=True, kernel_initializer='he_normal', name='lstm_2f')(em1)\n",
    "    lstm_2b = LSTM(rnn_stack, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='lstm_2b')(em1)\n",
    "    lstm2_merged = concatenate([lstm_2f, lstm_2b])\n",
    "    em2 = Dense(len(symbol_string)+1)(lstm2_merged)\n",
    "    y_pred = Activation('softmax', name='softmax')(em2)\n",
    "    # transforms RNN output to character activations:\n",
    "    #inner = Dense(len(symbol_string)+1, kernel_initializer='he_normal', name='dense2')(concatenate([lstm_2f, lstm_2b]))\n",
    "    #y_pred = Activation('softmax', name='softmax')(inner)\n",
    "    \n",
    "    Model(inputs=input_data, outputs=y_pred).summary()\n",
    "\n",
    "#---------------------------------------------------Got the outputs-------------------------------------------\n",
    "\n",
    "    labels = Input(name='labels', shape=[absolute_length], dtype='float32')\n",
    "    input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "    label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    "    \n",
    "    # Keras doesn't currently support loss funcs with extra parameters so CTC loss is implemented in a lambda layer\n",
    "    \n",
    "    loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\n",
    "    \n",
    "    #adam = Adam(lr=0.025, beta_1=0.9, beta_2=0.999, epsilon=1e-8, decay=1e-6)\n",
    "    sgd = SGD(lr=0.02, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=5)   # clip the gradients\n",
    "\n",
    "    model = Model(inputs=[input_data, labels, input_length, label_length], outputs=loss_out)\n",
    "\n",
    "    # the loss calc occurs elsewhere, so use a dummy lambda func for the loss\n",
    "    model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=sgd)\n",
    "    \n",
    "    if start_epoch > 0:\n",
    "        weight_file = os.path.join(OUTPUT_DIR, os.path.join(run_name, 'weights%02d.h5' % (start_epoch - 1)))\n",
    "        model.load_weights(weight_file)\n",
    "        \n",
    "        \n",
    "    test_func = K.function([input_data], [y_pred])\n",
    "    \n",
    "    \n",
    "    if training_method=='Generator':\n",
    "        Feed = Text_Image_Feed_Generator(symbol_string, input_dir, num_samples, validation_words, mini_batch_size, image_width, image_height, shrink_factor, absolute_length=absolute_length)\n",
    "        \n",
    "        viz_cb = Visuals(run_name, test_func, Feed.next_val())\n",
    "    \n",
    "    \n",
    "        steps = (num_samples - validation_words) // mini_batch_size\n",
    "        val_steps = validation_words // mini_batch_size\n",
    "\n",
    "        model.fit_generator(generator=Feed.next_train(), steps_per_epoch=steps, initial_epoch=start_epoch, epochs=end_epoch,\n",
    "                            validation_data=Feed.next_val(), validation_steps=val_steps,\n",
    "                            callbacks=[viz_cb, Feed])\n",
    "        \n",
    "    elif training_method=='Manual':\n",
    "        Feed=0\n",
    "        i, o = get_x_y(file_name, image_width, shrink_factor)\n",
    "        i_eval = {'inputs': i['inputs'][:1000], 'labels': i['labels'][:1000], 'input_length': i['input_length'][:1000], 'label_length': i['label_length'][:1000], 'source_str': i['source_str'][:1000]}\n",
    "        o_eval = {'ctc': o['ctc'][:1000]}\n",
    "        \n",
    "        viz = Visuals_manual(run_name, test_func, i_eval, o_eval)\n",
    "          \n",
    "        model.fit(x=i, y=o, batch_size=mini_batch_size, epochs=end_epoch, initial_epoch=start_epoch, callbacks=[viz], \n",
    "                  validation_split=split_ratio, shuffle=True)\n",
    "        \n",
    "    else:\n",
    "        raise ValueError('Please enter valid methon : Generator/Manual')\n",
    "        \n",
    "                               \n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "OUTPUT_DIR = 'image_hindi_ocr'                          \n",
    "symbol_string =u'\\u0900'u'\\u0901'u'\\u0902'u'\\u0903'u'\\u0904'u'\\u0905'u'\\u0906'u'\\u0907'u'\\u0908'u'\\u0909'u'\\u090A'u'\\u090B'u'\\u090C'u'\\u090D'u'\\u090E'u'\\u090F'u'\\u0910'u'\\u0911'u'\\u0912'u'\\u0913'u'\\u0914'u'\\u0915'u'\\u0916'u'\\u0917'u'\\u0918'u'\\u0919'u'\\u091A'u'\\u091B'u'\\u091C'u'\\u091D'u'\\u091E'u'\\u091F'u'\\u0920'u'\\u0921'u'\\u0922'u'\\u0923'u'\\u0924'u'\\u0925'u'\\u0926'u'\\u0927'u'\\u0928'u'\\u0929'u'\\u092A'u'\\u092B'u'\\u092C'u'\\u092D'u'\\u092E'u'\\u092F'u'\\u0930'u'\\u0931'u'\\u0932'u'\\u0933'u'\\u0934'u'\\u0935'u'\\u0936'u'\\u0937'u'\\u0938'u'\\u0939'u'\\u093A'u'\\u093B'u'\\u093C'u'\\u093D'u'\\u093E'u'\\u093F'u'\\u0940'u'\\u0941'u'\\u0942'u'\\u0943'u'\\u0944'u'\\u0945'u'\\u0946'u'\\u0947'u'\\u0948'u'\\u0949'u'\\u094A'u'\\u094B'u'\\u094C'u'\\u094D'u'\\u094E'u'\\u094F'u'\\u0950'u'\\u0951'u'\\u0952'u'\\u0953'u'\\u0954'u'\\u0955'u'\\u0956'u'\\u0957'u'\\u0958'u'\\u0959'u'\\u095A'u'\\u095B'u'\\u095C'u'\\u095D'u'\\u095E'u'\\u095F'u'\\u0960'u'\\u0961'u'\\u0962'u'\\u0963'u'\\u0964'u'\\u0965'u'\\u0966'u'\\u0967'u'\\u0968'u'\\u0969'u'\\u096A'u'\\u096B'u'\\u096C'u'\\u096D'u'\\u096E'u'\\u096F'u'\\u0970'u'\\u0971'u'\\u0972'u'\\u0973'u'\\u0974'u'\\u0975'u'\\u0976'u'\\u0977'u'\\u0978'u'\\u0979'u'\\u097A'u'\\u097B'u'\\u097C'u'\\u097D'u'\\u097E'u'\\u097F'u'!\"#$%&\\'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{|}~£Â '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "OUTPUT_DIR = 'total_ocr'                          \n",
    "symbol_string =u'\\u0900'u'\\u0901'u'\\u0902'u'\\u0903'u'\\u0904'u'\\u0905'u'\\u0906'u'\\u0907'u'\\u0908'u'\\u0909'u'\\u090A'u'\\u090B'u'\\u090C'u'\\u090D'u'\\u090E'u'\\u090F'u'\\u0910'u'\\u0911'u'\\u0912'u'\\u0913'u'\\u0914'u'\\u0915'u'\\u0916'u'\\u0917'u'\\u0918'u'\\u0919'u'\\u091A'u'\\u091B'u'\\u091C'u'\\u091D'u'\\u091E'u'\\u091F'u'\\u0920'u'\\u0921'u'\\u0922'u'\\u0923'u'\\u0924'u'\\u0925'u'\\u0926'u'\\u0927'u'\\u0928'u'\\u0929'u'\\u092A'u'\\u092B'u'\\u092C'u'\\u092D'u'\\u092E'u'\\u092F'u'\\u0930'u'\\u0931'u'\\u0932'u'\\u0933'u'\\u0934'u'\\u0935'u'\\u0936'u'\\u0937'u'\\u0938'u'\\u0939'u'\\u093A'u'\\u093B'u'\\u093C'u'\\u093D'u'\\u093E'u'\\u093F'u'\\u0940'u'\\u0941'u'\\u0942'u'\\u0943'u'\\u0944'u'\\u0945'u'\\u0946'u'\\u0947'u'\\u0948'u'\\u0949'u'\\u094A'u'\\u094B'u'\\u094C'u'\\u094D'u'\\u094E'u'\\u094F'u'\\u0950'u'\\u0951'u'\\u0952'u'\\u0953'u'\\u0954'u'\\u0955'u'\\u0956'u'\\u0957'u'\\u0958'u'\\u0959'u'\\u095A'u'\\u095B'u'\\u095C'u'\\u095D'u'\\u095E'u'\\u095F'u'\\u0960'u'\\u0961'u'\\u0962'u'\\u0963'u'\\u0964'u'\\u0965'u'\\u0966'u'\\u0967'u'\\u0968'u'\\u0969'u'\\u096A'u'\\u096B'u'\\u096C'u'\\u096D'u'\\u096E'u'\\u096F'u'\\u0970'u'\\u0971'u'\\u0972'u'\\u0973'u'\\u0974'u'\\u0975'u'\\u0976'u'\\u0977'u'\\u0978'u'\\u0979'u'\\u097A'u'\\u097B'u'\\u097C'u'\\u097D'u'\\u097E'u'\\u097F'u'!\"#$%&\\'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{|}~£Â 'u'\\u0A81'u'\\u0A82'u'\\u0A83'u'\\u0A85'u'\\u0A86'u'\\u0A87'u'\\u0A88'u'\\u0A89'u'\\u0A8A'u'\\u0A8B'u'\\u0A8C'u'\\u0A8D'u'\\u0A8F'u'\\u0A90'u'\\u0A91'u'\\u0A93'u'\\u0A94'u'\\u0A95'u'\\u0A96'u'\\u0A97'u'\\u0A98'u'\\u0A99'u'\\u0A9A'u'\\u0A9B'u'\\u0A9C'u'\\u0A9D'u'\\u0A9E'u'\\u0A9F'u'\\u0AA0'u'\\u0AA1'u'\\u0AA2'u'\\u0AA3'u'\\u0AA4'u'\\u0AA5'u'\\u0AA6'u'\\u0AA7'u'\\u0AA8'u'\\u0AAA'u'\\u0AAB'u'\\u0AAC'u'\\u0AAD'u'\\u0AAE'u'\\u0AAF'u'\\u0AB0'u'\\u0AB2'u'\\u0AB3'u'\\u0AB5'u'\\u0AB6'u'\\u0AB7'u'\\u0AB8'u'\\u0AB9'u'\\u0ABC'u'\\u0ABD'u'\\u0ABE'u'\\u0ABF'u'\\u0AC0'u'\\u0AC1'u'\\u0AC2'u'\\u0AC3'u'\\u0AC4'u'\\u0AC5'u'\\u0AC7'u'\\u0AC8'u'\\u0AC9'u'\\u0ACB'u'\\u0ACC'u'\\u0ACD'u'\\u0AD0'u'\\u0AE0'u'\\u0AE1'u'\\u0AE2'u'\\u0AE3'u'\\u0AE6'u'\\u0AE7'u'\\u0AE8'u'\\u0AE9'u'\\u0AEA'u'\\u0AEB'u'\\u0AEC'u'\\u0AED'u'\\u0AEE'u'\\u0AEF'u'\\u0AF0'u'\\u0AF1'u'\\u0AF9'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             (None, 128, 64, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 128, 64, 64)  640         inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 64, 32, 64)   0           conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 64, 32, 128)  73856       max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 32, 16, 128)  0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 32, 16, 256)  295168      max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 16, 256)  1024        conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32, 16, 256)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 32, 16, 256)  590080      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D) (None, 16, 8, 256)   0           conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 16, 8, 512)   1180160     max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 8, 512)   2048        conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16, 8, 512)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 16, 8, 512)   2359808     activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling2D) (None, 16, 4, 512)   0           conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 16, 4, 512)   1049088     max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 4, 512)   2048        conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 16, 4, 512)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling2D) (None, 16, 2, 512)   0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 16, 1, 512)   1049088     max_pooling2d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 16, 1, 512)   2048        conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 16, 1, 512)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 16, 512)      0           activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1f (LSTM)                  (None, 16, 512)      2099200     reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1b (LSTM)                  (None, 16, 512)      2099200     reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 16, 1024)     0           lstm_1f[0][0]                    \n",
      "                                                                 lstm_1b[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 16, 512)      524800      concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2f (LSTM)                  (None, 16, 512)      2099200     dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2b (LSTM)                  (None, 16, 512)      2099200     dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 16, 1024)     0           lstm_2f[0][0]                    \n",
      "                                                                 lstm_2b[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 16, 226)      231650      concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Activation)            (None, 16, 226)      0           dense_6[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 15,758,306\n",
      "Trainable params: 15,754,722\n",
      "Non-trainable params: 3,584\n",
      "__________________________________________________________________________________________________\n",
      "Train on 28800 samples, validate on 3200 samples\n",
      "Epoch 2/2\n",
      "28800/28800 [==============================] - 327s 11ms/step - loss: 23.4862 - val_loss: 23.4983\n",
      "['क', 'ा']\n",
      "['क', 'ा']\n",
      "['क', 'ा']\n",
      "['क', 'ा']\n",
      "['क', 'ा']\n",
      "['क', 'ा']\n",
      "['क', 'ा']\n",
      "['क', 'ा']\n",
      "Real = 'Mama --  Pred = 'का'\n",
      "Real = '$11bn --  Pred = 'का'\n",
      "Real = 'has 54 --  Pred = 'का'\n",
      "Real = 'सं. १८ --  Pred = 'का'\n",
      "Real = 'से मथ --  Pred = 'का'\n",
      "Real = 'कसी को --  Pred = 'का'\n",
      "Real = 'तरह थे --  Pred = 'का'\n",
      "Real = '\"Blair --  Pred = 'का'\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    #run_name = datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S')   #%Y-%m-%d-%H-%M-%S\n",
    "    #run_name = '2018-06-25-11-39-38'\n",
    "    train(run_name, 1, 2, 128, num_samples=320, mini_batch_size=32, training_method='Manual', file_name='C:/Users/Jay Chakalasiya/AnacondaProjects/OCR - Baidu/Inputs/HE Set/128-32000-NR-NY-NF-1.pickle')\n",
    "    #train(run_name, 46, 47, 192, num_samples=32000, mini_batch_size=32, training_method='Manual', file_name='C:/Users/Jay Chakalasiya/AnacondaProjects/Ipython/OCR/Inputs/Wordset/192/file0Image_data-192-set-1.pickle')\n",
    "    #train(run_name, 47, 48, 192, num_samples=32000, mini_batch_size=32, training_method='Manual', file_name='C:/Users/Jay Chakalasiya/AnacondaProjects/Ipython/OCR/Inputs/Wordset/192/file1Image_data-192-set-0.pickle')\n",
    "    #train(run_name, 48, 49, 192, num_samples=32000, mini_batch_size=32, training_method='Manual', file_name='C:/Users/Jay Chakalasiya/AnacondaProjects/Ipython/OCR/Inputs/Wordset/192/file1Image_data-192-set-1.pickle')\n",
    "    #train(run_name, 49, 50, 192, num_samples=32000, mini_batch_size=32, training_method='Manual', file_name='C:/Users/Jay Chakalasiya/AnacondaProjects/Ipython/OCR/Inputs/Wordset/192/file2Image_data-192-set-0.pickle')\n",
    "    #train(run_name, 50, 51, 192, num_samples=32000, mini_batch_size=32, training_method='Manual', file_name='C:/Users/Jay Chakalasiya/AnacondaProjects/Ipython/OCR/Inputs/Wordset/192/file2Image_data-192-set-1.pickle')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(int(-5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "str=''\n",
    "x_l = ['8','9','A','B','C','D','E','F']\n",
    "y_l = ['0','1','2','3','4','5','6','7','8','9','A','B','C','D','E','F']\n",
    "for x in x_l:\n",
    "    for y in y_l:\n",
    "        str+='u\\'\\\\u0A'+x+y+'\\','\n",
    "#k = 'u\\'\\\\u09'+x+y+'\\','\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"u'\\\\u0A80',u'\\\\u0A81',u'\\\\u0A82',u'\\\\u0A83',u'\\\\u0A84',u'\\\\u0A85',u'\\\\u0A86',u'\\\\u0A87',u'\\\\u0A88',u'\\\\u0A89',u'\\\\u0A8A',u'\\\\u0A8B',u'\\\\u0A8C',u'\\\\u0A8D',u'\\\\u0A8E',u'\\\\u0A8F',u'\\\\u0A90',u'\\\\u0A91',u'\\\\u0A92',u'\\\\u0A93',u'\\\\u0A94',u'\\\\u0A95',u'\\\\u0A96',u'\\\\u0A97',u'\\\\u0A98',u'\\\\u0A99',u'\\\\u0A9A',u'\\\\u0A9B',u'\\\\u0A9C',u'\\\\u0A9D',u'\\\\u0A9E',u'\\\\u0A9F',u'\\\\u0AA0',u'\\\\u0AA1',u'\\\\u0AA2',u'\\\\u0AA3',u'\\\\u0AA4',u'\\\\u0AA5',u'\\\\u0AA6',u'\\\\u0AA7',u'\\\\u0AA8',u'\\\\u0AA9',u'\\\\u0AAA',u'\\\\u0AAB',u'\\\\u0AAC',u'\\\\u0AAD',u'\\\\u0AAE',u'\\\\u0AAF',u'\\\\u0AB0',u'\\\\u0AB1',u'\\\\u0AB2',u'\\\\u0AB3',u'\\\\u0AB4',u'\\\\u0AB5',u'\\\\u0AB6',u'\\\\u0AB7',u'\\\\u0AB8',u'\\\\u0AB9',u'\\\\u0ABA',u'\\\\u0ABB',u'\\\\u0ABC',u'\\\\u0ABD',u'\\\\u0ABE',u'\\\\u0ABF',u'\\\\u0AC0',u'\\\\u0AC1',u'\\\\u0AC2',u'\\\\u0AC3',u'\\\\u0AC4',u'\\\\u0AC5',u'\\\\u0AC6',u'\\\\u0AC7',u'\\\\u0AC8',u'\\\\u0AC9',u'\\\\u0ACA',u'\\\\u0ACB',u'\\\\u0ACC',u'\\\\u0ACD',u'\\\\u0ACE',u'\\\\u0ACF',u'\\\\u0AD0',u'\\\\u0AD1',u'\\\\u0AD2',u'\\\\u0AD3',u'\\\\u0AD4',u'\\\\u0AD5',u'\\\\u0AD6',u'\\\\u0AD7',u'\\\\u0AD8',u'\\\\u0AD9',u'\\\\u0ADA',u'\\\\u0ADB',u'\\\\u0ADC',u'\\\\u0ADD',u'\\\\u0ADE',u'\\\\u0ADF',u'\\\\u0AE0',u'\\\\u0AE1',u'\\\\u0AE2',u'\\\\u0AE3',u'\\\\u0AE4',u'\\\\u0AE5',u'\\\\u0AE6',u'\\\\u0AE7',u'\\\\u0AE8',u'\\\\u0AE9',u'\\\\u0AEA',u'\\\\u0AEB',u'\\\\u0AEC',u'\\\\u0AED',u'\\\\u0AEE',u'\\\\u0AEF',u'\\\\u0AF0',u'\\\\u0AF1',u'\\\\u0AF2',u'\\\\u0AF3',u'\\\\u0AF4',u'\\\\u0AF5',u'\\\\u0AF6',u'\\\\u0AF7',u'\\\\u0AF8',u'\\\\u0AF9',u'\\\\u0AFA',u'\\\\u0AFB',u'\\\\u0AFC',u'\\\\u0AFD',u'\\\\u0AFE',u'\\\\u0AFF',\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ઁંઃઅઆઇઈઉઊઋઌઍએઐઑઓઔકખગઘઙચછજઝઞટઠડઢણતથદધનપફબભમયરલળવશષસહ઼ઽાિીુૂૃૄૅેૈૉોૌ્ૐૠૡૢૣ૦૧૨૩૪૫૬૭૮૯૰૱ૹ'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u'\\u0A81'u'\\u0A82'u'\\u0A83'u'\\u0A85'u'\\u0A86'u'\\u0A87'u'\\u0A88'u'\\u0A89'u'\\u0A8A'u'\\u0A8B'u'\\u0A8C'u'\\u0A8D'u'\\u0A8F'u'\\u0A90'u'\\u0A91'u'\\u0A93'u'\\u0A94'u'\\u0A95'u'\\u0A96'u'\\u0A97'u'\\u0A98'u'\\u0A99'u'\\u0A9A'u'\\u0A9B'u'\\u0A9C'u'\\u0A9D'u'\\u0A9E'u'\\u0A9F'u'\\u0AA0'u'\\u0AA1'u'\\u0AA2'u'\\u0AA3'u'\\u0AA4'u'\\u0AA5'u'\\u0AA6'u'\\u0AA7'u'\\u0AA8'u'\\u0AAA'u'\\u0AAB'u'\\u0AAC'u'\\u0AAD'u'\\u0AAE'u'\\u0AAF'u'\\u0AB0'u'\\u0AB2'u'\\u0AB3'u'\\u0AB5'u'\\u0AB6'u'\\u0AB7'u'\\u0AB8'u'\\u0AB9'u'\\u0ABC'u'\\u0ABD'u'\\u0ABE'u'\\u0ABF'u'\\u0AC0'u'\\u0AC1'u'\\u0AC2'u'\\u0AC3'u'\\u0AC4'u'\\u0AC5'u'\\u0AC7'u'\\u0AC8'u'\\u0AC9'u'\\u0ACB'u'\\u0ACC'u'\\u0ACD'u'\\u0AD0'u'\\u0AE0'u'\\u0AE1'u'\\u0AE2'u'\\u0AE3'u'\\u0AE6'u'\\u0AE7'u'\\u0AE8'u'\\u0AE9'u'\\u0AEA'u'\\u0AEB'u'\\u0AEC'u'\\u0AED'u'\\u0AEE'u'\\u0AEF'u'\\u0AF0'u'\\u0AF1'u'\\u0AF9'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = u'\\u092E'u'\\u093A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = paint_it(k, 64, 64, 'Inputs', True, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img.reshape((64,64))\n",
    "import numpy as np\n",
    "import cv2\n",
    "cv2.namedWindow('image', cv2.WINDOW_NORMAL)\n",
    "cv2.imshow('image',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'म'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ऺ'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'मऺ'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
